{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9cc884",
   "metadata": {},
   "source": [
    "\n",
    "# LSTM Example – Sentiment Analysis on IMDB Reviews  \n",
    "\n",
    "This notebook demonstrates building a **Bidirectional LSTM** using **TensorFlow/Keras** to classify movie reviews by sentiment.\n",
    "\n",
    "**Learning goals**  \n",
    "1. Load the IMDB dataset via `tensorflow_datasets`.  \n",
    "2. Tokenise & pad text, build train/val/test splits.  \n",
    "3. Baseline bag‑of‑words logistic regression.  \n",
    "4. Build, train & tune an LSTM.  \n",
    "5. Evaluate with accuracy & confusion matrix.  \n",
    "6. Save model + tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install -q tensorflow tensorflow_datasets scikit-learn matplotlib seaborn\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np, matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(ds_train_raw, ds_test_raw), info = tfds.load('imdb_reviews', split=['train', 'test'], with_info=True, as_supervised=True)\n",
    "BUFFER = 20000\n",
    "ds_train_raw = ds_train_raw.shuffle(BUFFER, reshuffle_each_iteration=False)\n",
    "train_size = int(0.8 * info.splits['train'].num_examples)\n",
    "ds_val_raw = ds_train_raw.skip(train_size)\n",
    "ds_train_raw = ds_train_raw.take(train_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bea735",
   "metadata": {},
   "source": [
    "### Baseline - TF‑IDF Bag‑of‑Words + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9352d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Baseline  —  TF‑IDF Bag‑of‑Words + Logistic Regression\n",
    "# ------------------------------------------------------------------\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1. Collect raw texts and labels from the TensorFlow‑datasets splits\n",
    "train_texts = [t.numpy().decode('utf‑8') for t, _ in ds_train_raw]   # ds_train_raw from earlier\n",
    "train_labels = [int(l.numpy()) for _, l in ds_train_raw]\n",
    "\n",
    "val_texts   = [t.numpy().decode('utf‑8') for t, _ in ds_val_raw]\n",
    "val_labels  = [int(l.numpy()) for _, l in ds_val_raw]\n",
    "\n",
    "test_texts  = [t.numpy().decode('utf‑8') for t, _ in ds_test_raw]\n",
    "test_labels = [int(l.numpy()) for _, l in ds_test_raw]\n",
    "\n",
    "# 2. Text → TF‑IDF vectors\n",
    "# Use TfidfVectorizer \n",
    "# create X_train, X_val, X_test\n",
    "\n",
    "#  Train Logistic Regression\n",
    "\n",
    "#  Evaluate\n",
    "\n",
    "# Print validation accuracy, test accuracy, classification report, confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82ee9ee",
   "metadata": {},
   "source": [
    "### Model with bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=20000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts([text.numpy().decode() for text,_ in ds_train_raw])\n",
    "MAXLEN = 300\n",
    "def encode(text,label):\n",
    "    seq = tokenizer.texts_to_sequences([text.numpy().decode()])[0]\n",
    "    seq = tf.keras.preprocessing.sequence.pad_sequences([seq], maxlen=MAXLEN, padding='post')[0]\n",
    "    return seq, label\n",
    "def tf_encode(text,label):\n",
    "    seq, label = tf.py_function(encode, inp=[text,label], Tout=[tf.int64, tf.int64])\n",
    "    seq.set_shape([MAXLEN]); label.set_shape([]); return seq, label\n",
    "batch=64\n",
    "train_ds = ds_train_raw.map(tf_encode).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = ds_val_raw.map(tf_encode).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds  = ds_test_raw.map(tf_encode).batch(batch).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2946326",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the LSTM model with tf.keras.Sequential\n",
    "# Add Embedding layer, Bidirectional LSTM layers, Dense layers\n",
    "# Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d382fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_true, y_pred = [], []\n",
    "# Evaluate the model\n",
    "# Print evaluation reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d31b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8885c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save('imdb_lstm_model.keras')\n",
    "with open('tokenizer.json','w') as f:\n",
    "    f.write(tokenizer.to_json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13774d38",
   "metadata": {},
   "source": [
    "### Compare the LSTM and Tf-Idf+LR evaluation results\n",
    "Provide your analysis on the observations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
